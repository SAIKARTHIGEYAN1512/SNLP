{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word_embedding.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO9Skw5deys0R6+vl4Cfg3D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SAIKARTHIGEYAN1512/SNLP/blob/master/word_embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHOjitjTJPTP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVqnaI0kJg7u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_layer = layers.Embedding(1000, 5)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSpqeFjbJkI1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "19544fd1-c2ea-442f-b6ca-253605fab438"
      },
      "source": [
        "result = embedding_layer(tf.constant([1,2,3]))\n",
        "result.numpy()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.01295639, -0.01742864,  0.00978468, -0.01784465, -0.044724  ],\n",
              "       [-0.04566658, -0.04795233,  0.01705867,  0.04895754, -0.04112607],\n",
              "       [ 0.02776045, -0.02332877,  0.01878455, -0.0283838 ,  0.04917992]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtCeP498Josi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c5861a7e-4bf2-45f6-b8f7-fe3c4a0285fc"
      },
      "source": [
        "result = embedding_layer(tf.constant([[0,1,2],[3,4,5]]))\n",
        "result.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 3, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oGsdzXBJrle",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "f934ab7f-cc0f-455f-f9a0-f5010f074c3a"
      },
      "source": [
        "(train_data, test_data), info = tfds.load(\n",
        "    'imdb_reviews/subwords8k', \n",
        "    split = (tfds.Split.TRAIN, tfds.Split.TEST), \n",
        "    with_info=True, as_supervised=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset imdb_reviews/subwords8k/1.0.0 (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to /root/tensorflow_datasets/imdb_reviews/subwords8k/1.0.0...\u001b[0m\n",
            "Shuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/subwords8k/1.0.0.incomplete0ZLTSE/imdb_reviews-train.tfrecord\n",
            "Shuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/subwords8k/1.0.0.incomplete0ZLTSE/imdb_reviews-test.tfrecord\n",
            "Shuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/subwords8k/1.0.0.incomplete0ZLTSE/imdb_reviews-unsupervised.tfrecord\n",
            "\u001b[1mDataset imdb_reviews downloaded and prepared to /root/tensorflow_datasets/imdb_reviews/subwords8k/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBb-0j53J85t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "c4206cd1-2649-4228-b553-ca4c99a91a07"
      },
      "source": [
        "encoder = info.features['text'].encoder\n",
        "encoder.subwords[:20]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the_',\n",
              " ', ',\n",
              " '. ',\n",
              " 'a_',\n",
              " 'and_',\n",
              " 'of_',\n",
              " 'to_',\n",
              " 's_',\n",
              " 'is_',\n",
              " 'br',\n",
              " 'in_',\n",
              " 'I_',\n",
              " 'that_',\n",
              " 'this_',\n",
              " 'it_',\n",
              " ' /><',\n",
              " ' />',\n",
              " 'was_',\n",
              " 'The_',\n",
              " 'as_']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eUPpTaCKAfx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_batches = train_data.shuffle(1000).padded_batch(10)\n",
        "test_batches = test_data.shuffle(1000).padded_batch(10)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npvH6J5sKC4X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "1cd2a628-f6bb-47b5-a78b-ff8e0de51cde"
      },
      "source": [
        "train_batch, train_labels = next(iter(train_batches))\n",
        "train_batch.numpy()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2383, 1782, 4013, ...,    0,    0,    0],\n",
              "       [  12,   31,  456, ...,    0,    0,    0],\n",
              "       [  19, 2031,   18, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [1342,   15,   56, ...,    0,    0,    0],\n",
              "       [  62,   27,    9, ...,    0,    0,    0],\n",
              "       [  12, 5705, 7961, ...,    0,    0,    0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLxh2EFvKF_S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "ee6c3348-dd7d-4399-f620-dee9a45cbb5e"
      },
      "source": [
        "embedding_dim=16\n",
        "\n",
        "model = keras.Sequential([\n",
        "  layers.Embedding(encoder.vocab_size, embedding_dim),\n",
        "  layers.GlobalAveragePooling1D(),\n",
        "  layers.Dense(16, activation='relu'),\n",
        "  layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 16)          130960    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 131,249\n",
            "Trainable params: 131,249\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0bTZQK7KHK2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "409b9b5b-fa47-4106-88f4-038ecc77cd30"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_batches,\n",
        "    epochs=10,\n",
        "    validation_data=test_batches, validation_steps=20)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2500/2500 [==============================] - 12s 5ms/step - loss: 0.5118 - accuracy: 0.6966 - val_loss: 0.4272 - val_accuracy: 0.8250\n",
            "Epoch 2/10\n",
            "2500/2500 [==============================] - 12s 5ms/step - loss: 0.2843 - accuracy: 0.8847 - val_loss: 0.3669 - val_accuracy: 0.8400\n",
            "Epoch 3/10\n",
            "2500/2500 [==============================] - 11s 4ms/step - loss: 0.2292 - accuracy: 0.9092 - val_loss: 0.4808 - val_accuracy: 0.8050\n",
            "Epoch 4/10\n",
            "2500/2500 [==============================] - 11s 4ms/step - loss: 0.1995 - accuracy: 0.9228 - val_loss: 0.3896 - val_accuracy: 0.8600\n",
            "Epoch 5/10\n",
            "2500/2500 [==============================] - 11s 4ms/step - loss: 0.1764 - accuracy: 0.9339 - val_loss: 0.3828 - val_accuracy: 0.8650\n",
            "Epoch 6/10\n",
            "2500/2500 [==============================] - 12s 5ms/step - loss: 0.1578 - accuracy: 0.9420 - val_loss: 0.3692 - val_accuracy: 0.9000\n",
            "Epoch 7/10\n",
            "2500/2500 [==============================] - 12s 5ms/step - loss: 0.1448 - accuracy: 0.9467 - val_loss: 0.4881 - val_accuracy: 0.8200\n",
            "Epoch 8/10\n",
            "2500/2500 [==============================] - 11s 4ms/step - loss: 0.1328 - accuracy: 0.9524 - val_loss: 0.5684 - val_accuracy: 0.8000\n",
            "Epoch 9/10\n",
            "2500/2500 [==============================] - 11s 5ms/step - loss: 0.1195 - accuracy: 0.9583 - val_loss: 0.5853 - val_accuracy: 0.8000\n",
            "Epoch 10/10\n",
            "2500/2500 [==============================] - 12s 5ms/step - loss: 0.1123 - accuracy: 0.9598 - val_loss: 0.6443 - val_accuracy: 0.8350\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZlOrTc5KO7A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "be46232b-b930-4eec-e135-fc12f8398b12"
      },
      "source": [
        "e = model.layers[0]\n",
        "weights = e.get_weights()[0]\n",
        "print(weights.shape) "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8185, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNJ6HPgXKRg5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "\n",
        "encoder = info.features['text'].encoder\n",
        "\n",
        "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "for num, word in enumerate(encoder.subwords):\n",
        "  vec = weights[num+1] \n",
        "  out_m.write(word + \"\\n\")\n",
        "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": 15,
      "outputs": []
    }
  ]
}